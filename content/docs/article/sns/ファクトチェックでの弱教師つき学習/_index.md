---
title: "ファクトチェックでの弱教師つき学習"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---

# Weakly Supervised Learning for Fake News Detection on Twitter

[論文はこちら](https://data.dws.informatik.uni-mannheim.de/fakenews/asonam_short.pdf)

著者：Stefan Helmstetter, Heiko Paulheim

4ページしかない(迫真)

# Introduction

人の手でファクトチェックやるコストがあまりに高すぎる。汚れたデータのままで学習してみるよ。

fake news自体の**Tweetを使うより、発信ユーザの信頼できるorできないを判断する野を目標**にするよ。信頼できるユーザが少しfakeを流すとしてもそれは仕方ないと判断。

手法は、**弱教師つき学習(Weakly Supervised Learning)**を使う。

精度高かったよ。F1スコアで0.9にもなった。

# 関連研究

今までの研究はみな

- データ量が少なさすぎる。
- 局限する分野が狭すぎる。
- 各タスクに限定したもので、人の手でアノテーションしたものしか訓練データにならない。

という欠点があった。この研究では、わずかの信頼できる、できないというアノテーションから、大きな未アノテーションのデータへ適用できる。

# データセット

大きなデータセットと、小さな手動でラベル付けしたデータセットを用意したよ。

## 大きなデータセット

まずは、信頼できる発信者と信頼できない発信者を集めることから始めた。

ここで、**ツイートごとにfake or not fakeでラベル付けする**。fake newsの発信者であっても、虚実入り混じる発信をすることに注意。

65のfake newsの発信者を集めた。信頼できるのは10人ほど集めた。当然これらは、積極的にTwitterに発信することが前提である。データセットのバランスを合わせるのも忘れずに。

Twitterでそれらのアカウントの2月から6月分のTweetを集めた。合わせて401414件あり、110787件がfakeと、ラベル付けされた。
fake newsのアカウントは15%のfakeと40%の真実、残りはニュースじゃないTweetであった。

重要な事実として、嘘つきも、真実の割合が嘘に比べて3倍ぐらい多いのである。なので普通に判断させるとfake newsのソースも信頼できる、と扱われる。

でも仕方ないんだ。アノテーションに手間かけられないしガバガバなのは許せ。by me. 

## 小さなデータセット

絶対的基準として、Politifactからの116ツイートを使った。これはプロの記者がつけたもの。fake newsに対して、絶対的な正答例として使うことに。

これらのツイートしたアカウントと、大きなデータセットで追跡したアカウントは**必ずしも一致しない**ことに注意。

ネガティブな例を生成するとかなんとか。ようわからん。

類似度判定自体は、cos類似度やTF-IDFだそうで。

これトレーニングに使わなかったの...? by me.

## 評価シナリオ

**ツイートだけ見て評価する or ツイートとプロフィール両方**見ての判断。

# 手法

まずは各ツイートをベクトルに変換。そしていろんな手法でそのベクトルから特徴量を抽出する。特徴量には5種類あると考えた。

## ユーザーレベルの特徴

ユーザーのフォロワー数などの、TwitterAPIで取得できる限りのものを集めた。ツイート頻度、Tweet/Retweetの割合など。計53個集めたよ。

## ツイートレベルの特徴

これもAPIで取得できる限りのもの。？と！の出現頻度、Tweetの日時、Tweet数、語数を使った。69の特徴量を使った。

**ただし、経過した時間依存のfavとRT数は使用しなかった**。

## テキストの特徴

TF-IDFを使ったbag of wordモデルと、Doc2Vecのモデル両方を使った。(注：今BARDあるから後者でよくね？)gensimという埋め込み生成を使った。ラベルなし学習でできるし。

## トピックの特徴

トピックはかなり重要なので、Tweet文から抽出させるようにして、別途やることにした。遅延ディリクレ配置LDAモデルを訓練した。トピック数を10から200まで10刻みで動かした。

## 感情の特徴

SentiWordNetで各ツイートのpositive, negative, neutral wordの数を測定した。さらにTextBlobでtweetの客観性を計算した。

これらから8つの特徴量を追加した。

## 次元圧縮

さすがにこれらは多すぎるので、落とします。各特徴量のジニ係数？を計算し、一定以下の者は全て消した。

## 学習アルゴリズムとパラメタ最適化

Naive Bayes、Decision Tree, SVM, Nueral networkの4つを基本的な分類器とした。アンサンブルの手法のRandom ForestとXGBoostも行った。

# 実験結果

まずは、**偽ニュースのソースについての特定**をやってみた。クロス評価を行った。**ユーザー情報を追加したほうが、明らかにファクトチェックではいい成績を残す**。一番よかったのは、XGBoostでF1値がツイートだけは0.78、ユーザとツイート合わせては0.94と高かった。

次に、**偽ニュースのツイートについての特定**をやってみた。こっちの方がまあ、難しいわけです。こっちはニューラルネットワークの方が性能良かった！

# 結論

大きな不正確なアノテーションのデータでもいい結果が残せるで。しかもかなり良い結果ちゃうか？


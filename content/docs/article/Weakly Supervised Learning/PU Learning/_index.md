---
title: "Learning Classifiers from Only Positive and Unlabeled Data"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---

[元論文](https://cseweb.ucsd.edu/~elkan/posonly.pdf)

参考にしたサイトたち

https://mamo3gr.hatenablog.com/entry/2020/11/29/123147

https://speakerdeck.com/hellorusk/pu-positive-unlabeled-learning?slide=3

# 何なの？

ラベルはいっぱいあるけどつけるの間に合わん。普通はPositiveとNegativeにつけられたデータで行うが、PU Learningは**PositiveとUnknownで区分したデータで学習させる**。

生成モデルに基づく半教師付きの手法と違って、分布を仮定する必要はない。

# 手法

手法自体は結構単純だが、確率変数$s$で定式化したものは初出である。

## 仮定、説明

サンプル$x \in \mathbb{R}$について、
- 正答$y \in 0, 1$があり、**1ならPositive、0ならNegative**である。
- ラベル$s \in 0, 1$があり、**1ならラベルあり、0ならラベルなし**

そして、未知だが$(x, y, s)$に**対する不変の分布がある**とする。

仮定として、Positiveなものしかラベル付けされてない、しかも一部。つまり**NegativeはUnknownである**。$p(s = 1| x, y = 0) = 0$

もう1つ仮定として、ラベル付けされるPositiveは、**Positiveの全体からランダムに選ばれると仮定する**。$p(s = 1 | x, y = 1) = p(s = 1 | y = 1) = 一定値c$。$x$に関係なく、取るという意味。

## 理論的なおはなし

条件付確率の分解をやる。「xであるときにy=1」$p(y = 1 | x)$と「xであって、y=1であるときにs=1」$p(s | x, y = 1)$の積。依存関係はあるが関係はない。

$$
p(s = 1 | x) = p(y = 1, s = 1 | x) = p(y = 1 | x) p (s = 1 | x, y = 1) = p(y = 1 | x) \cdot c
$$

つまり、

$$
p(y = 1 | x) = \frac{p(s = 1 | x)}{c}
$$

つまり、データに対してPositiveである確率は、以下のものがわかる。

1. $p(s = 1 | x)$　　データ$x$に対して、それがラベル付きかどうか。**これは通常の分類器で推定できるので問題なし**。
   1. 実際にやる場合、SVMならば正例の重みを強くして学習する？
   2. 全部のデータと実際のラベル付きデータはあるんで、その分布を仮定する手法ならなんでも。深層学習でもいい。
2. $c = p(s = 1 | y = 1)$　　Positiveなラベルなら、印がつく確率。
3. ついでにいえば、確率なので、$p(s = 1 | x) \leq c = p(s = 1 | y = 1)$である。これは、どのデータにおいても、$p(s = +1 | \mathbf{x})$は実際において真と確定したもののラベルの付く確率以下とわかる。
   1. どのデータも未確定か、確定しても同じ$p(s = 1 | y = 1)$なので。未確定の場合はそもそもNegativeならラベルが付かないことをも考えると妥当。

よって、一番欲しい$p(y = 1 | x)$推定できる。

## 定数$c$の推定方法

というわけで、**$c = p(s = 1 | y = 1)$を推定することができれば、勝ちです**。
ちゃんと無限のデータで訓練し、真のモデルで学習できる前提だと3つの手法のいずれも正しい。だが実用上は手法1がいい。

### 手法1

$$
c = p(s = 1 | y = 1) = \frac{p(s = 1 | \mathbf{x})}{p(y = 1 | \mathbf{x})}
$$

全体の中でのある一部のデータセット$(\mathbf{x}, y, s) \in V$があるとする。**この中で$(\mathbf{x}, y = +1, s = +1) \in P$のものだけに着目し、これらの中での印がついてるものの割合を見ればよい**。それが$c = \frac{p(s = 1 | \mathbf{x})}{p(y = 1 | \mathbf{x})}$の割合となれる。

すべての$p(s = 1 | \mathbf{x})$の設計が正しければこれは正しいが、実際は有限の訓練データ、モデルの概形によってうまく行かないのがふつうである。
ただ、**実際で使う分にもこれが一番の精度である**。手法2は分母で分散が更に加わる。手法3は1つの変数、こちらは平均なので分散のブレが小さい。

### 手法2

同様に$V, P$を使って以下のように推定する。

$$
\frac{\sum _{\mathbf{x} \in P} p(s = +1 | \mathbf{x})}{\sum _{\mathbf{x} \in V} p(s = +1 | \mathbf{x})}
$$

これは、同じ基準で測量している以上、分母と分子での和の比がそのまま$V$と$P$の比に近似され、これは$(\mathbf{x}, y, s) \in V, (\mathbf{x}, y = +1, s = +1) \in P$に他ならないからである。

### 手法3

$$
\max _{\mathbf{x} \in V} p(s = 1 | \mathbf{x}) < c = p(s = 1 | y = 1)
$$

$p(s = 1 | y = 1)$が$p(s = 1 | \mathbf{x})$にとっての最大なので、集めてきた$p(s = 1 | \mathbf{x})$が最大のものとすればよい。
$p(s = 1 | \mathbf{x})$はあらかじめ別口で学習させておく。ただ理論上は等号成立するが01損失で学習をしない以上ここら辺は曖昧になりそう？ INTEREST!

---

## 重み付きElkan Noto

前述のとおり、$p(s = 1 | x)$「**データ$x$に対して、それがラベル付きかどうか**」。これは学習器で学習できる。その学習器に入れた時の結果を$g(x)$と置く。

$c = p(s = 1 | y = 1)$**Positiveなラベルなら、印がつく確率**。

ここで、訓練データと同じように抽出したテストデータ集合$V$を考える。**その中で、ラベルの付いてる集合**を$P$とする。

$$
c = \frac{1}{n} \sum \limits_{x \in P} g(x)
$$

つまり、$V$**のなかで実際にラベル付きのデータに対して、分類器でラベル付き=1か否か=0**を**、$|P|=n$**で割った平均**。$|V|$**ではない！**。これは**実際にラベル付きのデータに対してどれぐらい正確に予測できてるか**、ということを示す。

そして、分類器が正しく**訓練データについて**$p(s = 1 | x)$を学習できてるなら、これは**テストデータ(そしては訓練データ以外の全体のデータ)に対して、真のPositiveのデータのうち、ラベル付けされてるサンプルの割合**になる。

つまり、ちゃんと訓練データに対して学習をさせたから(もちろんその訓練データの中でまた訓練とテストに分けるけど)、同じ分布(未知だけど)に従ってPositiveのものにラベルがつくと仮定してる以上、**すでにラベルついてるデータに対して予測器でラベルつく割合を見つけられれば、それは全体のPositiveの者に対して、ラベル付きであるの割合だと**なる。

実際はだいたいそうならない。ちゃんと同じ分布に従うかな？でもこの手法はそれなりに正しいんですよこれ。

### 手法2

先ほどは、$p(y = 1 | x) = \frac{p(s = 1 | x)}{c}$で$p(y = 1 | x)$を求めた。

今度は、まず$p(s = 1 | x)$を学習してみる。次に

- **ラベル付きはそのまま**。
- **ラベルなしは、ラベルあり=重み**$w(x)$と**ラベルなし=重み**$1 - w(x)$**という2つの点に複製する。そして、もう一度、$p(s = 1 | x)$を重みつきで学習する。**

なお、重みは、$w(x) = p(y = 1 | x, s = 0)$とする。

![](image0.jpg)

こんな風に、**一度方法1から予測した**$c$から計算できる。

そして、これらの重みをそれぞれつけなおしたものから、もう一度$p(s = 1 | x)$を学習させるのだ。

### 実際の学習のフェーズ

実際、識別器はSVMのソフトマージンで実装される。だが、SVMのソフトマージンでの定式化での損失関数はヒンジ損失$z$を用いると、

$$
\frac{1}{2} || \mathbf{w} || + C_p \sum _{i \in P} z_i + C_U \sum _{j \in U} z_j
$$

この$C_P, C_U$は**経験則で決めるしかない**らしい。この手法をこの論文が**biased-SVM**と提案している。

- $C_U = 0.01, 0.03, 0.05, \cdots, 0.61$
- $\frac{C_P}{C_U} = 10, 20, \cdots, 200$
- **$C_P$に大きく重みを寄せる**。

### 評価

**手法2の方が実験的に精度が良い**。

どっちも、(論文は2だけ離散の分類器は無理らしいけど、全部離散は無理では？？？)分類器が離散だとNGらしい。

また、理論的に正しく境界を決めるには、誤差関数をnon-convex loss(SVMのhinge lossはNG)にしないとならないという難点がある。


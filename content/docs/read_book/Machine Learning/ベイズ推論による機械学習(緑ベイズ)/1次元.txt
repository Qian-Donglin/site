## 1次元ガウス分布

ガウス分布はハイパーパラメタとして、平均値$\mu$、分散$\sigma ^ 2$の2つがあり、どれを学習するのかで話が変わる。なお、精度$\lambda = \frac{1}{\sigma ^ 2}$とする。

### 平均の推定

観測値$x$に対して、ガウス分布を考える。平均だけ推定するので、精度$\lambda$は既知だとする。

$$
p(x | \mu) = \mathcal{N} (x | \mu, \lambda ^ {-1})
$$

この平均値$\mu$自体の事前分布も、共役事前分布の別のガウス分布に従うとする。$m, \lambda _{\mu}$はハイパーパラメタ。

$$
p(\mu) = \mathcal{N}(\mu | m, \lambda _{\mu} ^ {-1})
$$

今回、一連の観測データ$\mathbf{x} = (x_1, \cdots, x_n)$を得たとする。ここから事後分布$p(\mu | \mathbf{x})$を学習する。

$$
p(\mu | \mathbf{x}) \propto p(\mathbf{x} | \mu) p(\mu)
= \prod _{i = 1} ^ N (\mathcal{N} (x_i | \mu, \lambda ^ {-1})) \cdot \mathcal{N} (\mu | m, \lambda _{\mu} ^ {-1}) \\\\ 
$$

ここで、掛け算なので正規分布の再生性は使えない。対数を取って丁寧に計算していく。

$$
\log \mathcal{N} (x | \mu, \lambda ^ {-1}) = \frac{1}{2} \log \lambda - \frac{1}{2} \log 2 \pi - \frac{(x - \mu) ^ 2}{2} \lambda
$$

であるので、

$$
\log p(\mu | \mathbf{x}) \propto \frac{1}{2}(\log \lambda ^ {N} \lambda _{\mu}) - \frac{N + 1}{2} \log 2\pi - \frac{\lambda}{2} \sum _{i = 1} ^ {N} (x_i - \mu) ^ 2 - \frac{\lambda _{\mu}}{2} (\mu - m) ^ 2f \\\\ 
= -\frac{1}{2} \mu ^ 2 (\lambda N + \lambda _{\mu}) + \mu (\lambda _{\mu} m + \lambda \sum _{i = 1} ^ N x_i) + \mathrm{const}
$$

天下り的に計算するとこれは、$p(\mu | \mathbf{x}) = \mathcal{N} (\mu | \hat{m}, \hat{\lambda _{\mu}})$と分布を書くと、

$$
\hat{\lambda _{\mu}} = N \lambda + \lambda _{\mu} \\\\ 
\hat{m} = \frac{1}{\hat{\lambda _{\mu}}} (\lambda \sum _{i = 1} ^ N x_i + \lambda _{\mu} m)
$$

これが意味するのは、

- **$\hat{m}$は観測データを集めれば集めるほど、当初の事前分布の期待値$m$の影響が薄まり、代わりに学習した$x_i$が決定に寄与する**ようになるということ。
- **$\hat{\lambda _{\mu}}$は観測データを集めれば集めるほど高くなる=分散は小さくなる**。つまり、観測データが集まるほど、$\mu$の事後分布のばらつきは小さくなる。

次は同様に予測分布を計算する。

$$
p(x _{pred}) = \int p(x _{pred} | \mu) p(\mu) d\mu
= \int \mathcal{N} (x _{pred} | \mu, \lambda ^ {-1}) \mathcal{N} (\mu | m, \lambda _{\mu} ^ {-1}) d\mu \\\\ 
\log p(x _{pred} | \mu) p(\mu) = \frac{1}{2} (\log \lambda + \lambda _{\mu}) - \frac{1}{2} (\log 2 \pi) - \frac{1}{2}(\lambda(x _{pred} - \mu) ^ 2 + \lambda _{\mu} (\mu - m) ^ 2) \\\\ 
= -\frac{1}{2} \mu ^ 2 (\lambda + \lambda _{\mu}) + 2\mu (\lambda x _{pred} + \lambda _{\mu} m) + \mathrm{const}
$$

同様に、予測分布$p(x _{pred}) = \mathcal{N} (x _{pred} | \hat{m}, \hat{\lambda})$として、

$$
\frac{1}{\hat{\lambda}} = \frac{1}{\lambda} + \frac{1}{\lambda _{\mu}} \\\\ 
\hat{m} = m
$$

となる。予測分布の期待値はまさに事前分布$p(\mu)$の期待値そのものであり、**予測分布の分散は事前分布と観測分布の分散の和であると言える**。

### 精度が未知の場合

平均$\mu$は既知であるが、精度$\lambda$を学習したい場合を考える。データ$x$は次の分布に従う。

$$
p(x | \lambda) = \mathcal{N}(x | \mu, \lambda ^ {-1})
$$

パラメタ$\lambda$は次の事前分布に従うとする。γ分布を選ぶことで、共役事前分布となる。

$$
p(\lambda) = \Gamma(\lambda | a, b) = \frac{b ^ a}{\Gamma(a)} \lambda ^ {a - 1} e ^ {-b \lambda}
$$

学習するデータは複数個あると考えると、$p(\mathbf{x} | \lambda) = \prod _{i = 1} ^ N p(x_i | \lambda)$

ここで、ベイズの定理を使って同様に事後確率$p(\lambda | \mathbf{x})$を学習してみる。

$$
p(\lambda | \mathbf{x}) \propto p(\mathbf{x} | \lambda) p(\lambda) = \mathcal{N}(\mathbf{x} | \mu, \lambda ^ {-1}) \Gamma(\lambda | a, b)
$$

ここで、確率密度関数の対数はそれぞれ以下のとおりである。

$$
\log \mathcal{N} (x | \mu, \lambda ^ {-1}) = \frac{1}{2} \log \lambda - \frac{1}{2} \log 2 \pi - \frac{(x - \mu) ^ 2}{2} \lambda \\\\ 
\log \Gamma(\lambda | a, b) = a \log b - \log \Gamma(a) + (a - 1) \log \lambda - b \lambda
$$

これを使って、$p(\lambda | \mathbf{x})$を計算し、そこから$\lambda$に関係する項だけを選び出すと、

$$
p(\mathbf{x} | \lambda) p(\lambda) = \mathcal{N}(\mathbf{x} | \mu, \lambda ^ {-1}) \Gamma(\lambda | a, b) = \prod _{i = 1} ^ N \mathcal{N}(x | \mu, \lambda ^ {-1}) \Gamma(\lambda | a, b)\\\\ 
= \frac{N}{2}(\log \lambda - \log 2 \pi) - \frac{\lambda}{2} \sum _{i = 1} ^ N (x _i - \mu) ^ 2 + a \log b - \log \Gamma(a) + (a - 1) \log \lambda - b\lambda \\\\ 
= -\lambda (\frac{1}{2} \sum _{i = 1} ^ N (x _i - \mu) ^ 2 + b) + \log \lambda (\frac{N}{2} - a + 1) + \mathrm{const}
$$

この形はγ分布の対数版と同じ形であるので、この形は$\Gamma(\lambda | \hat{a}, \hat{b})$として、

$$
\hat{a} = \frac{N}{2} + a \\\\ 
\hat{b} = \frac{1}{2} \sum _{i = 1} ^ N (x _i - \mu) ^ 2 + b
$$

これが意味することは、ようわからん。パラメタの更新がこんな風ってことかな...?

次は例によって予測分布を計算する。

$$
p(x _{pred}) = \int p(x _{pred} | \lambda) p(\lambda) d \lambda = \int \mathcal{N} (x _{pred} | \mu, \lambda ^ {-1}) \Gamma(\lambda | a, b) d \lambda
$$

これは計算してもいいが、ベイズの定理$p(\lambda | x _{pred}) = \frac{p(x _{pred} | \lambda) p(\lambda)}{p(x _{pred})}$を対数を取って、$p(\lambda)$の項を無視すれば、

$$
\log p(x _{pred}) = \log p(x _{pred} | \lambda) - \log p(\lambda | x _{pred}) + \mathrm{const}
$$

これから計算を進めると、

$$
\log p(x _{pred}) = -\frac{2a + 1}{2} \log (1 + \frac{1}{2b} (x _{pred} - \mu) ^ 2) + \mathrm{const}
$$

これは実はstudentのt分布である。

### 平均と精度いずれも未知である。

$$
p(x | \mu, \lambda) = \mathcal{N} (x | \mu, \lambda ^ {-1})
$$

この時、事前分布は以下のようなガウス・γ分布である。なお、お互いに独立である(はず)ので、上記のようなガウス分布、γ分布でそれぞれやってもよいが、1つにまとめられる感じ。ハイパーパラメタは$m, \beta, a, b$。同様にデータは複数個ある$\mathbf{x}$と考える。

$$
\mathcal{N} (\mu | m, (\beta \lambda) ^ {-1}) \mathrm{Gam} (\lambda | a, b)
$$

事後分布は、以下の値となる。

$$
\mathcal{N} (x | \mu, \lambda ^ {-1}) \mathcal{N} (\mu | m, (\beta \lambda) ^ {-1}) \mathrm{Gam} (\lambda | a, b)
$$

先ほどの平均、精度での計算法を流用すると、まずは前二項から平均を計算する。これは平均計算のパートと同じなので、流用すると

$$
\hat{\beta} = N + \beta \\\\ 
\hat{m} = \frac{1}{\hat{\beta}} (\sum _{i = 1} ^ N x _n + \beta m) 
$$
<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="元論文
日本語解説はどうやらないみたい。
こっちのGitHubレポジトリに3mの発表動画やスライドがある。テストコードも。
Introduction # Positiveデータしか持たないが、その中で各データに信頼度というパラメタがある。Unknown、Negativeはない。
1クラス分類はあるが、ハイパーパラメタの調整ができない手法しかなかった。しかも、どんなにデータを増やしても、分布の境界を予測はできない。類似したものを見つけることができても、分類=境界線をいい感じに引く、ことはできない。
このPConfは、ハイパーパラメタを客観的に選ぶこともできる。これは、ERM(経験損失最小化 = 選んだ標本誤差の最小化)を使って実現されている。
PU学習とも似てる手法ではあるが、PU学習で必要なPositiveのデータの事前確率の推定(2007年のPU学習では、$p(ラベル付き|データ)$を推定していた(結局あんま精度高くないよね)　これを指してるのだと思う)は不要。これを高精度で求めるのは苦労がかかるので、朗報。実は各データについての信頼度という情報には、事前確率、条件付確率、事後確率はすべて含まれている。
問題の定式化 # データは$\mathbf{x} \in \mathbb{R}^d$の形。ラベルは二値分類なので、$-1, 1$。これらは、未知の分布関数$p(\mathbf{x}, y)$に従う。
実現したいのは、$g(\mathbf{}) : \mathbb{R}^d \to \mathbb{R}$という二値分類器(出力が二値ではないのは、確からしさを残すため？ by me)
例によって、損失がどれぐらい出てくるのかのリスク関数を定義する。
$$ R(g) = \mathbb{E} _{p(\mathbf{x}, y)} [l(y g(\mathbf{x}))] $$
$l(m)$は損失関数。ラベルと予測器が同じ符合なら$l(m)$は0に、違う符合なら関数に渡されるのは負値で、より自信満々に間違えるほど大きな負値を渡すことになる。$l(m)$は大きなマイナスほど大きな値を返す。
例によって、このリスク関数を最小化していく。
ここで、$p(\mathbf{x}, y)$は未知なので、普通のERM(経験損失最小化)では、真の期待値を今あるテストデータの期待値で代用する。それはそう。しかし、PConfでは、違う。
PConfでは、与えられたデータ群(と言ってもPositiveしかないが)に対して、$\chi$という集合で、信頼度を定義する。
$$ \chi := (\mathbf{x}_i, r_i) で、iは全てのデータ $$
$r_i$は各データの信頼度
$$ r_i = p(y = &#43;1 | \mathbf{x}_i) $$
$\mathbf{x}_i$はあるデータを全数つかわない場合、データ群から一様ランダムに抽出したものである。
Negativeデータがないので、普通のERMの計算方法ではリスク関数を計算するできない。次のセクションでは信頼度で代わりに表示する方法を表す。
PConf分類のやり方 # ERM(経験損失最小化)の枠組み # $\pi _{&#43;} = p(y=&#43;1)$これは全データのうち、Positiveのデータの割合。あれ、Negativeとか見えないんじゃなかったっけ？by me">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="Positive Confidential Learning(2017)" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://Qian-Donglin.github.io/docs/article/Weakly-Supervised-Learning/Positive-Confidential-learning2017/" />

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css"
	integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"
	integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx"
	crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"
	integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
	onload="renderMathInElement(document.body);"></script>

<script>
	document.addEventListener("DOMContentLoaded", function () {
		renderMathInElement(
			document.body,
			{
				delimiters: [
					{ left: "$$", right: "$$", display: true },
					{ left: "\\[", right: "\\]", display: true },
					{ left: "$", right: "$", display: false },
					{ left: "\\(", right: "\\)", display: false }
				]
			});
	});
</script>

<title>Positive Confidential Learning(2017) | Sen(Qian)のメモ</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/%20favicon.png">
<link rel="stylesheet" href="/book.min.f8de3645fe00591b41524aee174e19edd98a22255a2930a0cdc82a94835ba387.css" integrity="sha256-&#43;N42Rf4AWRtBUkruF04Z7dmKIiVaKTCgzcgqlINbo4c=" crossorigin="anonymous">
<script defer src="/%20flexsearch.min.js"></script>
<script defer src="/en.search.min.43d9e1a27caa5999a7fee1bb577c631649e74ee5e89bedb7682f0f3f87c303eb.js" integrity="sha256-Q9nhonyqWZmn/uG7V3xjFknnTuXom&#43;23aC8PP4fDA&#43;s=" crossorigin="anonymous"></script>

<link rel="alternate" type="application/rss+xml" href="https://Qian-Donglin.github.io/docs/article/Weakly-Supervised-Learning/Positive-Confidential-learning2017/index.xml" title="Sen(Qian)のメモ" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Sen(Qian)のメモ</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/editorial/" class="">競プロの問題解説</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <span>Dp</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/editorial/DP/%E6%A1%81DP/" class="">桁 Dp</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/editorial/DP/%E6%A1%81DP/Y-abc317-F/" class="">(Y-) abc317 F</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-0d2a02cd744e63233ebe57612bb12952" class="toggle"  />
    <label for="section-0d2a02cd744e63233ebe57612bb12952" class="flex justify-between">
      <a role="button" class="">Grid</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/editorial/Grid/G-abc317-E/" class="">(G&#43;) abc317 E</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>Implement</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/editorial/Implement/G-abc315-E/" class="">(G) Abc315 E Index</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cea18f1d04185b9a1f879558d5aeddb2" class="toggle"  />
    <label for="section-cea18f1d04185b9a1f879558d5aeddb2" class="flex justify-between">
      <a role="button" class="">Square Divide</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/editorial/SquareDivide/CABC293-E%E5%B9%B3%E6%96%B9%E5%88%86%E5%89%B2/" class="">(C) abc293 E(平方分割)</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-52d2a0ea11310952e77a5e1d9b1ee709" class="toggle"  />
    <label for="section-52d2a0ea11310952e77a5e1d9b1ee709" class="flex justify-between">
      <a role="button" class="">Graph</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/editorial/Graph/BrABC292-D/" class="">(Br) abc292 D</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>読んだ本</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <span>Machine Learning</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <span>ベイズ推論による機械学習(緑ベイズ)</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/read_book/Machine-Learning/%E3%83%99%E3%82%A4%E3%82%BA%E6%8E%A8%E8%AB%96%E3%81%AB%E3%82%88%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%B7%91%E3%83%99%E3%82%A4%E3%82%BA/section-1/" class="">第一章</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/read_book/Machine-Learning/%E3%83%99%E3%82%A4%E3%82%BA%E6%8E%A8%E8%AB%96%E3%81%AB%E3%82%88%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%B7%91%E3%83%99%E3%82%A4%E3%82%BA/section-2/" class="">第二章</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/read_book/Machine-Learning/%E3%83%99%E3%82%A4%E3%82%BA%E6%8E%A8%E8%AB%96%E3%81%AB%E3%82%88%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%B7%91%E3%83%99%E3%82%A4%E3%82%BA/section-3-part1/" class="">第三章その1</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/read_book/Machine-Learning/%E3%83%99%E3%82%A4%E3%82%BA%E6%8E%A8%E8%AB%96%E3%81%AB%E3%82%88%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%B7%91%E3%83%99%E3%82%A4%E3%82%BA/section-3-part2/" class="">第三章その2</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-3c22cc3dba3e6e6de0eab46bcb97d14b" class="toggle" checked />
    <label for="section-3c22cc3dba3e6e6de0eab46bcb97d14b" class="flex justify-between">
      <a role="button" class="">読んだ論文たちのメモ</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d64fdaa8e46f50c67b163d98fad0ddb7" class="toggle"  />
    <label for="section-d64fdaa8e46f50c67b163d98fad0ddb7" class="flex justify-between">
      <a role="button" class="">Graphic Design</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/article/graphic_design_ML/Content-aware-Generative-Modeling-of-Graphic-Design-Layouts/" class="">Content Aware Generative Modeling of Graphic Design Layouts</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/graphic_design_ML/Learning-to-Generate-Posters-of-Scientific-Papers/" class="">Learning to Generate Posters of Scientific Papers</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>Order Thing</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/article/order_thing/Learning-to-Order-Thing/" class="">Learning to Order Thing</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-749fb68fcedaafaff7bdd8e5931b0451" class="toggle"  />
    <label for="section-749fb68fcedaafaff7bdd8e5931b0451" class="flex justify-between">
      <a role="button" class="">sns</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/article/sns/%E7%82%8E%E4%B8%8A%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/" class="">Twitterの炎上について</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/sns/%E3%83%95%E3%82%A1%E3%82%AF%E3%83%88%E3%83%81%E3%82%A7%E3%83%83%E3%82%AF%E3%81%A7%E3%81%AE%E5%BC%B1%E6%95%99%E5%B8%AB%E3%81%A4%E3%81%8D%E5%AD%A6%E7%BF%92/" class="">ファクトチェックでの弱教師つき学習</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/sns/%E5%BC%B1%E6%95%99%E5%B8%AB%E5%AD%A6%E7%BF%92%E3%81%A7%E3%83%AA%E3%83%97%E3%83%A9%E3%82%A4%E3%81%8B%E3%82%89%E7%82%8E%E4%B8%8A%E5%88%86%E6%9E%90/" class="">弱教師学習でリプライから炎上分析</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-de33daac55650926621e120a75049e4a" class="toggle"  />
    <label for="section-de33daac55650926621e120a75049e4a" class="flex justify-between">
      <a role="button" class="">Svm</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/article/SVM/%E3%82%AB%E3%83%BC%E3%83%8D%E3%83%AB%E6%B3%95/" class="">カーネル法</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/SVM/%E3%82%BD%E3%83%95%E3%83%88%E3%83%9E%E3%83%BC%E3%82%B8%E3%83%B3/" class="">ソフトマージン</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/SVM/%E3%83%8F%E3%83%BC%E3%83%89%E3%83%9E%E3%83%BC%E3%82%B8%E3%83%B3/" class="">ハードマージン</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-0465dfafe9cdc495ea2e5d9009d8922a" class="toggle" checked />
    <label for="section-0465dfafe9cdc495ea2e5d9009d8922a" class="flex justify-between">
      <a role="button" class="">Weakly Supervised Learning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/2017%E6%99%82%E7%82%B9%E3%81%AE%E5%90%84%E6%89%8B%E6%B3%95/" class="">2017時点の各手法</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/PNU-Learning/" class="">PNU Learning(2017年)</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/Positive-Confidential-learning2017/" class="active">Positive Confidential Learning(2017)</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/Positive%E3%81%A7%E3%83%A9%E3%83%99%E3%83%AB%E6%9C%89%E3%82%8A%E7%84%A1%E3%81%97%E3%81%A7%E5%88%86%E5%B8%83%E3%81%8C%E9%81%95%E3%81%86%E6%99%82%E3%81%AEPU%E5%AD%A6%E7%BF%922019/" class="">Positiveでラベル有り無しで分布が違う時の PU学習(2019)</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/Positive%E3%81%A7%E3%83%A9%E3%83%99%E3%83%AB%E6%9C%89%E3%82%8A%E7%84%A1%E3%81%97%E3%81%A7%E5%88%86%E5%B8%83%E3%81%8C%E9%81%95%E3%81%86%E6%99%82%E3%81%AEPU%E5%AD%A6%E7%BF%922019/PU-Learning%E3%81%AE%E3%82%AF%E3%83%A9%E3%82%B9%E3%81%AE%E5%AE%9F%E8%A3%85/" class="">バイアスつきPU Learningクラスの実装</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/Positive%E3%81%A7%E3%83%A9%E3%83%99%E3%83%AB%E6%9C%89%E3%82%8A%E7%84%A1%E3%81%97%E3%81%A7%E5%88%86%E5%B8%83%E3%81%8C%E9%81%95%E3%81%86%E6%99%82%E3%81%AEPU%E5%AD%A6%E7%BF%922019/%E5%AE%9F%E9%A8%93%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89%E3%81%AE%E8%A7%A3%E6%9E%90/" class="">バイアスつきPU Learningクラスの実装</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/Positive%E3%81%A7%E3%83%A9%E3%83%99%E3%83%AB%E6%9C%89%E3%82%8A%E7%84%A1%E3%81%97%E3%81%A7%E5%88%86%E5%B8%83%E3%81%8C%E9%81%95%E3%81%86%E6%99%82%E3%81%AEPU%E5%AD%A6%E7%BF%922019/%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%B3%E3%83%BC%E3%83%89/" class="">メインコード</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/PU-Learning/" class="">PU Learning(2007年)</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/%E5%88%86%E5%B8%83%E4%BB%AE%E5%AE%9A%E4%B8%8D%E8%A6%81PU-Learning2014/" class="">PU LearningでなんでSVMのヒンジ関数は精度悪いか(2014)</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/article/Weakly-Supervised-Learning/%E8%A3%9C%E3%83%A9%E3%83%99%E3%83%AB%E5%AD%A6%E7%BF%922017/" class="">補ラベル学習(2017)</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Positive Confidential Learning(2017)</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#erm経験損失最小化の枠組み">ERM(経験損失最小化)の枠組み</a>
      <ul>
        <li><a href="#式変形の意味">式変形の意味</a></li>
        <li><a href="#本筋の続き">本筋の続き</a></li>
        <li><a href="#最適化問題だから分母消してもいいだろいいの">最適化問題だから分母消してもいいだろ←いいの？</a></li>
        <li><a href="#本筋に戻る">本筋に戻る</a></li>
      </ul>
    </li>
    <li><a href="#性能評価">性能評価</a></li>
    <li><a href="#実装するには">実装するには</a></li>
  </ul>

  <ul>
    <li><a href="#線形モデルの合成実験">線形モデルの合成実験</a></li>
    <li><a href="#dnnにおいての手法適用">DNNにおいての手法適用</a>
      <ul>
        <li><a href="#結果">結果</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><p>
  <a href="https://arxiv.org/abs/1710.07138">元論文</a></p>
<p>日本語解説はどうやらないみたい。</p>
<p>
  <a href="https://github.com/takashiishida/pconf">こっちのGitHubレポジトリ</a>に3mの発表動画やスライドがある。テストコードも。</p>
<h1 id="introduction">
  Introduction
  <a class="anchor" href="#introduction">#</a>
</h1>
<p>Positiveデータしか持たないが、その中で各データに信頼度というパラメタがある。Unknown、Negativeはない。</p>
<p>1クラス分類はあるが、ハイパーパラメタの調整ができない手法しかなかった。しかも、どんなにデータを増やしても、分布の境界を予測はできない。類似したものを見つけることができても、分類=境界線をいい感じに引く、ことはできない。</p>
<p>このPConfは、ハイパーパラメタを客観的に選ぶこともできる。これは、ERM(経験損失最小化 = <strong>選んだ標本誤差の最小化</strong>)を使って実現されている。</p>
<p>PU学習とも似てる手法ではあるが、PU学習で必要なPositiveのデータの事前確率の推定(2007年のPU学習では、$p(ラベル付き|データ)$を推定していた(結局あんま精度高くないよね)　これを指してるのだと思う)は<strong>不要</strong>。これを高精度で求めるのは苦労がかかるので、朗報。実は<strong>各データについての信頼度という情報には、事前確率、条件付確率、事後確率はすべて含まれている</strong>。</p>
<h1 id="問題の定式化">
  問題の定式化
  <a class="anchor" href="#%e5%95%8f%e9%a1%8c%e3%81%ae%e5%ae%9a%e5%bc%8f%e5%8c%96">#</a>
</h1>
<p>データは$\mathbf{x} \in \mathbb{R}^d$の形。ラベルは二値分類なので、$-1, 1$。これらは、未知の分布関数$p(\mathbf{x}, y)$に従う。</p>
<p><strong>実現したいのは、$g(\mathbf{}) : \mathbb{R}^d \to \mathbb{R}$という二値分類器</strong>(出力が二値ではないのは、確からしさを残すため？ by me)</p>
<p>例によって、損失がどれぐらい出てくるのかの<strong>リスク関数を定義</strong>する。</p>
<p>$$
R(g) = \mathbb{E} _{p(\mathbf{x}, y)} [l(y g(\mathbf{x}))]
$$</p>
<p>$l(m)$は損失関数。ラベルと予測器が同じ符合なら$l(m)$は0に、違う符合なら関数に渡されるのは負値で、<strong>より自信満々に間違えるほど大きな負値を渡す</strong>ことになる。$l(m)$は大きなマイナスほど大きな値を返す。</p>
<p>例によって、<strong>このリスク関数を最小化</strong>していく。</p>
<p>ここで、$p(\mathbf{x}, y)$は未知なので、普通のERM(経験損失最小化)では、真の期待値を今あるテストデータの期待値で代用する。それはそう。しかし、PConfでは、違う。</p>
<p>PConfでは、与えられたデータ群(と言ってもPositiveしかないが)に対して、<strong>$\chi$という集合で、信頼度を定義する</strong>。</p>
<p>$$
\chi := (\mathbf{x}_i, r_i) で、iは全てのデータ
$$</p>
<p>$r_i$は各データの信頼度</p>
<p>$$
r_i = p(y = +1 | \mathbf{x}_i)
$$</p>
<p>$\mathbf{x}_i$はあるデータを全数つかわない場合、データ群から一様ランダムに抽出したものである。</p>
<p>Negativeデータがないので、普通のERMの計算方法ではリスク関数を計算するできない。次のセクションでは信頼度で代わりに表示する方法を表す。</p>
<h1 id="pconf分類のやり方">
  PConf分類のやり方
  <a class="anchor" href="#pconf%e5%88%86%e9%a1%9e%e3%81%ae%e3%82%84%e3%82%8a%e6%96%b9">#</a>
</h1>
<h2 id="erm経験損失最小化の枠組み">
  ERM(経験損失最小化)の枠組み
  <a class="anchor" href="#erm%e7%b5%8c%e9%a8%93%e6%90%8d%e5%a4%b1%e6%9c%80%e5%b0%8f%e5%8c%96%e3%81%ae%e6%9e%a0%e7%b5%84%e3%81%bf">#</a>
</h2>
<p>$\pi _{+} = p(y=+1)$これは全データのうち、Positiveのデータの割合。あれ、Negativeとか見えないんじゃなかったっけ？by me</p>
<p>$r(\mathbf{x}) = p(y=+1 | \mathbf{x})$ $r_i$はデータ$\mathbf{x}_i$についての信頼度だった。これは、<strong>引数に渡したデータ$\mathbf{x}$の信頼度</strong>。</p>
<p>$\mathbb{E} _{+}$は、$\mathbb{E} _{p(\mathbf{x} | y = +1)}$の場合、つまり<strong>Positiveのデータに限った場合の条件付期待値</strong>である。これらを使って、以下のように$R(g)$を表せる。</p>
<p>$$
R(g) = \pi _{+} \mathbb{E} _{+} [ l(g(\mathbf{x})) + \frac{1 - r(\mathbf{x})}{r(\mathbf{x})} l(-g(\mathbf{x}))]
$$</p>
<p>当然だが全部Positiveなので、$r(\mathbf{x}) \neq 0$である。</p>
<h3 id="式変形の意味">
  式変形の意味
  <a class="anchor" href="#%e5%bc%8f%e5%a4%89%e5%bd%a2%e3%81%ae%e6%84%8f%e5%91%b3">#</a>
</h3>
<p>意味としては、以下の通り。(本来はAppendix Aにある)</p>
<p>$$
R(g) = \sum _{y = +1, -1} l(y g(\mathbf{x})) p(\mathbf{x}, y) d\mathbf{x} = \sum _{y = +1, -1} l(y g(\mathbf{x})) p(\mathbf{x}| y) p(y)d\mathbf{x}
$$</p>
<p>$\pi _{+} = p(y = +1)$、$\pi _{-} = p(y = -1)$は<strong>積分の外に出せる</strong>ので、</p>
<p>$$
=\pi _{+} \mathbb{E} _{p(\mathbf{x} | y = +1)} [l(yg(x))] + \pi _{-} \mathbb{E} _{p(\mathbf{x} | y = -1)} [l(-yg(x))]
$$</p>
<p>第2項では、$y=-1$なので損失関数のなかには負の符号がつく**。ここで、一旦以下の値の変形を見る。</p>
<p>$$
\pi _{+} p(\mathbf{x} | y = +1) + \pi _{-} p(\mathbf{x} | y = -1)
$$</p>
<p>$$
= p(\mathbf{x}, y = +1) + p(\mathbf{x}, y = -1) = p(\mathbf{x})
$$</p>
<p>$$
= \frac{p(\mathbf{x}, y = +1)}{p(p(y = +1 | \mathbf{x}))} = \frac{\pi _{+} p(\mathbf{x} | y = +1)}{r(\mathbf{x})}
$$</p>
<p>ここで、式の両辺に$\pi _{+} p(\mathbf{x} | y = +1)$が出てきてるので、$\pi _{-} p(\mathbf{x} | y = -1)$について解けば、</p>
<p>$$
\pi _{-} p(\mathbf{x} | y = -1) = \pi _{+} p(\mathbf{x} | y = +1) (\frac{1 - r(\mathbf{x})}{r(\mathbf{x})})
$$</p>
<p>とえられる。これを代入すれば元の式が得られる。</p>
<h3 id="本筋の続き">
  本筋の続き
  <a class="anchor" href="#%e6%9c%ac%e7%ad%8b%e3%81%ae%e7%b6%9a%e3%81%8d">#</a>
</h3>
<p>$$
R(g) = \pi _{+} \mathbb{E} _{+} [ l(g(\mathbf{x})) + \frac{1 - r(\mathbf{x})}{r(\mathbf{x})} l(-g(\mathbf{x}))]
$$</p>
<p>上のように上手いこと変形することで、Negativeのデータにおける期待値を消去してる。さらに言えばこの$R(g)$の最小化を考えるにあたり、未知の量$\pi _{+}$は比例定数なので考えなくてもいい。</p>
<p>では、この$R(g)$は理想的な分布を使っていたわけだが、これを実際にあるデータの平均で期待値を代用すると、以下のような最適化問題を解く形になる。</p>
<p>$$
\min _{g} \sum _{i = 1} ^ {n} [ l(g(\mathbf{x}_i)) + \frac{r_i}{1 - r_i} l(-g(\mathbf{x}_i)) ]
$$</p>
<h3 id="最適化問題だから分母消してもいいだろいいの">
  最適化問題だから分母消してもいいだろ←いいの？
  <a class="anchor" href="#%e6%9c%80%e9%81%a9%e5%8c%96%e5%95%8f%e9%a1%8c%e3%81%a0%e3%81%8b%e3%82%89%e5%88%86%e6%af%8d%e6%b6%88%e3%81%97%e3%81%a6%e3%82%82%e3%81%84%e3%81%84%e3%81%a0%e3%82%8d%e3%81%84%e3%81%84%e3%81%ae">#</a>
</h3>
<p>これに$r_i$を乗じた以下のもの</p>
<p>$$
\min _{g} \sum _{i = 1} ^ {n} [ r_i l(g(\mathbf{x}_i)) + (1 - r_i) l(-g(\mathbf{x}_i)) ]
$$</p>
<p>この式、更に簡約できる。</p>
<p>$$
= \min _{g} \sum _{i = 1} ^ {n} p(y = +1 | \mathbf{x}_i) l(g(\mathbf{x}_i)) + p(y = -1 | \mathbf{x}_i) l(-g(\mathbf{x}_i))
$$</p>
<p>$$
= \min _{g} \sum _{i = 1} ^ {n} \sum _{y = -1, 1} p(y | \mathbf{x}  _i) l(y g(\mathbf{x} _i))
$$</p>
<p>このように簡約できる。だが、実はこれは<strong>等価ではない</strong>。外側の$\sum$が、$p(\mathbf{x})$に対してだが、これが$p(\mathbf{x} | y = +1)$ならば正しい。なぜなら、$r_i=p(y = +1 | \mathbf{x}_i)$を掛けたので、</p>
<p>$$
p(\mathbf{x}_i | y = +1) = \frac{r_i p(\mathbf{x}_i)}{p(y = +1)}
$$</p>
<p>$$
r_i = \frac{p(\mathbf{x}_i | y = + 1) p(y = +1)}{p(\mathbf{x}_i)}
$$</p>
<p>ここで、$p(y = +1)$は定数？なので、まあ掛けないとあかん理由わかるね。</p>
<h3 id="本筋に戻る">
  本筋に戻る
  <a class="anchor" href="#%e6%9c%ac%e7%ad%8b%e3%81%ab%e6%88%bb%e3%82%8b">#</a>
</h3>
<p>
  <a href="https://qiita.com/s-yonekura/items/287631cc894e436fd1d4">重点サンプリングとは</a>　以下に簡単に書く。</p>
<p>$$
\mathbb{E} _{\mu} [f(x)] = \int f(x) \mu(x) dx = \int f(x) \frac{\mu(x)}{\nu(x)} \nu(x) dx
$$</p>
<p>$w(x) = \frac{\mu(x)}{\nu(x)}$と言い換えておくと、この上の式は</p>
<p>$$
\int f(x) w(x) \mu(x) dx = \mathbb{E} _{\nu} [ f(x)w(x) ]
$$</p>
<p>と言い換えられる。つまり、重み関数$w(x)$を掛ければ、別の分布についての期待値となる。この手法を重点サンプリング=Importance Samplingという。</p>
<p>上の2つの式は、互いに重点サンプリングである、とも見れる。$p(\mathbf{x})$と$p(\mathbf{x} | y = +1)$についての期待値。</p>
<h2 id="性能評価">
  性能評価
  <a class="anchor" href="#%e6%80%a7%e8%83%bd%e8%a9%95%e4%be%a1">#</a>
</h2>
<p>長すぎて略したい&hellip;むずかしいし。</p>
<p>結論として、</p>
<p>$$
\min _{g} \sum _{i = 1} ^ {n} [ l(g(\mathbf{x}_i)) + \frac{r_i}{1 - r_i} l(-g(\mathbf{x}_i)) ]
$$</p>
<p>は真のリスク関数に収束するが、</p>
<p>$$
\min _{g} \sum _{i = 1} ^ {n} \sum _{y = -1, 1} p(y | \mathbf{x}  _i) l(y g(\mathbf{x} _i))
$$</p>
<p>は真のリスク関数には収束しない。</p>
<h2 id="実装するには">
  実装するには
  <a class="anchor" href="#%e5%ae%9f%e8%a3%85%e3%81%99%e3%82%8b%e3%81%ab%e3%81%af">#</a>
</h2>
<p>$$
g(\mathbf{x}) = \mathbf{w} ^ T \mathbf{\Phi(\mathbf{x})}
$$</p>
<p>こんな風に線形識別器$g(\mathbf{x})$を作るとする。</p>
<p>L2正規化をしたERMは、以下の最小化を行う。$\lambda$は正規化定数であり、<strong>$R$は半正定値行列</strong>。</p>
<p>$$
\min _{\mathbf{a}} \frac{\lambda}{2} \mathbf{w} ^ T R \mathbf{w} + \sum _{i = 1} ^ {n} [ l( \mathbf{w}^T \mathbf{\Phi(\mathbf{x}_i)}) + \frac{r_i}{1 - r_i} l(-\mathbf{w}^T \mathbf{\Phi(\mathbf{x}_i)}) ]
$$</p>
<p>正規化項はいつもの$|| \mathbf{w} ||^2$ではないが、これは$R$が半正定値行列なので、コレスキー分解$R = C^T C$とすることができる。こうすると、$\mathbf{w} ^ T R \mathbf{w} = ((C\mathbf{w}) ^T (C\mathbf{w}))$と、別の線形空間に写像したうえでのL2正規化と見れる。</p>
<p>損失関数は</p>
<ul>
<li>$l(z) = (z - 1)^2$</li>
<li>$l(z) = \max(0, 1 - z)$</li>
<li>$l(z) = \log(1 + e^{-z})$ これが<strong>一番よかった</strong>。</li>
</ul>
<p>これは確率的勾配法とかを使えば最適化できる。</p>
<p>これ、**SVMで行けるんじゃね？？？？？**by me(たぶんやってる)</p>
<h1 id="実験">
  実験
  <a class="anchor" href="#%e5%ae%9f%e9%a8%93">#</a>
</h1>
<p><strong>どうやら線形モデルでも、DNNでも有効らしい。DNNで更に有効らしい</strong>。なんだこれは。</p>
<h2 id="線形モデルの合成実験">
  線形モデルの合成実験
  <a class="anchor" href="#%e7%b7%9a%e5%bd%a2%e3%83%a2%e3%83%87%e3%83%ab%e3%81%ae%e5%90%88%e6%88%90%e5%ae%9f%e9%a8%93">#</a>
</h2>
<p>平均が$\mathbf{\mu} _{+}, \mathbf{\mu} _{-}$であり、共分散行列が$\Sigma _{+} \Sigma _{-}$であるデータを使う。</p>
<ul>
<li>提案した手法</li>
<li>提案した手法に$r_i$掛けて、違うよね？とした手法</li>
<li>回帰ベースの手法。信頼度事態を予測して、0.5以上か以下で判断する</li>
<li>1クラスSVMはGaussianカーネルを使う。性質上、正例データのみ使う。</li>
<li>完全にラベル付けされた例も、比較実験として使う。</li>
</ul>
<p>提案手法、違うよね？手法、完全にラベル付けした手法は、$g(\mathbf{x}) = \mathbf{w} ^ T \mathbf{x} + b$を使ったらしい。最適化ではエポック数5000、学習率0.001で行った。</p>
<p>なお、$r(\mathbf{x})$はどう計算されるんだ？に関しては「<strong>2つのガウス密度から解析的に計算される</strong>」そう。なにこれ？？？<strong>何も言ってないけど、2つのクラスの真の中心の距離の逆比っすかね</strong>？？？まあ、$r(\mathbf{x}) = p(y = +1 | \mathbf{x})$なので、$p(\mathbf{x} | y = +1)$からベイズの定理で求めるのかね？</p>
<p>結果としては、<strong>提案手法のPConfは、完全にラベル判明したものと同等の精度があると判明</strong>。</p>
<p>なお、<strong>真の確信度わからずにガウス分布に従うノイズを加えると、性能が低下することにはするが、全然使える範囲</strong>でもあると。</p>
<h2 id="dnnにおいての手法適用">
  DNNにおいての手法適用
  <a class="anchor" href="#dnn%e3%81%ab%e3%81%8a%e3%81%84%e3%81%a6%e3%81%ae%e6%89%8b%e6%b3%95%e9%81%a9%e7%94%a8">#</a>
</h2>
<p>
  <a href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a>という服関連のデータセットでやった。1つのクラス(T-shirts Top)だけをPositive、他をNegativeにした。データは以下の4つに分ける。</p>
<ul>
<li>訓練</li>
<li>検証</li>
<li>テスト</li>
<li>Positiveのデータに対して、$r(\mathbf{x}_i)$を推定するための確率的分類器の学習用データ
<ul>
<li>本来は人がやるけど、ここはこれで代用や！</li>
<li>ロジスティック回帰で実装した。</li>
<li><strong>ここらの前提はまだそれなりにある　把握しきれない</strong>。</li>
</ul>
</li>
</ul>
<p>3つの隠れ層でそれぞれ100個のニューロンがあり、最後に1つで総結合するニューロンを持つネットワークで、活性化関数はReLU関数を使った。</p>
<p>あといろいろある。CIFAR-10についてもやってる。</p>
<h3 id="結果">
  結果
  <a class="anchor" href="#%e7%b5%90%e6%9e%9c">#</a>
</h3>
<p>提案したPconfはやはり素晴らしい性能だった。完全にラベル付けしたものの性能にも迫るぐらいね。</p>
<p>ほんへ終了</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/Qian-Donglin/site/commit/5384cd1a3ee076cecc31d316ca856eb301c31a34" title='Last modified by Donglin Qian | August 28, 2023' target="_blank" rel="noopener">
      <img src="/svg/calendar.svg" class="book-icon" alt="Calendar" />
      <span>August 28, 2023</span>
    </a>
  </div>




</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#erm経験損失最小化の枠組み">ERM(経験損失最小化)の枠組み</a>
      <ul>
        <li><a href="#式変形の意味">式変形の意味</a></li>
        <li><a href="#本筋の続き">本筋の続き</a></li>
        <li><a href="#最適化問題だから分母消してもいいだろいいの">最適化問題だから分母消してもいいだろ←いいの？</a></li>
        <li><a href="#本筋に戻る">本筋に戻る</a></li>
      </ul>
    </li>
    <li><a href="#性能評価">性能評価</a></li>
    <li><a href="#実装するには">実装するには</a></li>
  </ul>

  <ul>
    <li><a href="#線形モデルの合成実験">線形モデルの合成実験</a></li>
    <li><a href="#dnnにおいての手法適用">DNNにおいての手法適用</a>
      <ul>
        <li><a href="#結果">結果</a></li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












